{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import models from another notebook\n",
    "%run model.ipynb\n",
    "%run util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # params\n",
    "# parser = argparse.ArgumentParser(description='Process inputs for training a model')\n",
    "# parser.add_argument('--model_id', default='dense_model')\n",
    "# parser.add_argument('--dropout', default='0.4', type=float)\n",
    "# parser.add_argument('--layers_count', default='2', type=int)\n",
    "# parser.add_argument('--dense_units', default='64', type=int)\n",
    "# parser.add_argument('--hidden_activation', default='relu')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# print(\"Args: \" + str(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "### Load sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shape: (1000000, 2)\n",
      "Subset shape: (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "# load inputs\n",
    "sudokus = pd.read_csv('./datasets/sudoku-kaggle.csv')\n",
    "print(\"Full shape:\", sudokus.shape)\n",
    "subset = sudokus.sample(n=50000).values\n",
    "print(\"Subset shape:\", subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of puzzles: 50000\n",
      "Number of solutions: 50000\n"
     ]
    }
   ],
   "source": [
    "# Split into puzzles and solutions\n",
    "puzzles, solutions = subset[:, 0], subset[:, 1]\n",
    "print(\"Number of puzzles:\", len(puzzles))\n",
    "print(\"Number of solutions:\", len(solutions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of puzzles: (50000, 9, 9)\n",
      "Shape of solutions: (50000, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to 9x9\n",
    "reshape_f = lambda x: np.reshape([int(digit) for digit in x], (9, 9))\n",
    "reshaped_puzzles = np.array(list(map(reshape_f, puzzles)))\n",
    "reshaped_solutions = np.array(list(map(reshape_f, solutions)))\n",
    "print(\"Shape of puzzles:\", reshaped_puzzles.shape)\n",
    "print(\"Shape of solutions:\", reshaped_solutions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of puzzles: (50000, 9, 9, 10)\n",
      "Shape of solutions: (50000, 9, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "# To one-hot encoding\n",
    "one_hot_puzzles = to_one_hot(reshaped_puzzles)\n",
    "one_hot_solutions = to_one_hot(reshaped_solutions - 1)\n",
    "print(\"Shape of puzzles:\", one_hot_puzzles.shape)\n",
    "print(\"Shape of solutions:\", one_hot_solutions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (45000, 9, 9, 10)\n",
      "Training labels shape: (45000, 9, 9, 9)\n",
      "Testing data shape: (5000, 9, 9, 10)\n",
      "Testing labels shape: (5000, 9, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(one_hot_puzzles, one_hot_solutions, \n",
    "                                                    test_size=0.1, random_state=42)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40500, 9, 9, 10)\n",
      "Training labels shape: (40500, 9, 9, 9)\n",
      "Validating data shape: (4500, 9, 9, 10)\n",
      "Validating labels shape: (4500, 9, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Validating data shape:\", X_val.shape)\n",
    "print(\"Validating labels shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input shape: (?, 9, 9, 10)\n",
      "Model output shape: (?, 9, 9, 9)\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = get_model(X_train.shape[1:], y_train.shape[1:], model_id='dense_model')\n",
    "print(\"Model input shape:\", model.input.shape)\n",
    "print(\"Model output shape:\", model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40500/40500 [==============================] - 27s 674us/sample - loss: 170.4738 - acc: 0.5161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a09c041c50>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train model\n",
    "model.fit(delete_digits(X_train, 0), y_train, batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass n° 1 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "40500/40500 [==============================] - 30s 751us/sample - loss: 65.7735 - acc: 0.7813 - val_loss: 46.0901 - val_acc: 0.8476\n",
      "Pass n° 2 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/2\n",
      "40500/40500 [==============================] - 30s 753us/sample - loss: 66.3507 - acc: 0.7771 - val_loss: 48.3089 - val_acc: 0.8385\n",
      "Epoch 2/2\n",
      "40500/40500 [==============================] - 30s 752us/sample - loss: 64.4675 - acc: 0.7823 - val_loss: 47.9349 - val_acc: 0.8391\n",
      "Pass n° 3 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/4\n",
      "40500/40500 [==============================] - 30s 749us/sample - loss: 68.8511 - acc: 0.7655 - val_loss: 53.0911 - val_acc: 0.8196\n",
      "Epoch 2/4\n",
      "40500/40500 [==============================] - 30s 747us/sample - loss: 67.0898 - acc: 0.7706 - val_loss: 52.9694 - val_acc: 0.8193\n",
      "Epoch 3/4\n",
      "40500/40500 [==============================] - 31s 754us/sample - loss: 66.0665 - acc: 0.7733 - val_loss: 52.7915 - val_acc: 0.8190\n",
      "Epoch 4/4\n",
      "40500/40500 [==============================] - 30s 745us/sample - loss: 65.2668 - acc: 0.7754 - val_loss: 52.6642 - val_acc: 0.8190\n",
      "Pass n° 4 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/8\n",
      "40500/40500 [==============================] - 30s 749us/sample - loss: 75.7789 - acc: 0.7380 - val_loss: 62.9412 - val_acc: 0.7826\n",
      "Epoch 2/8\n",
      "40500/40500 [==============================] - 30s 751us/sample - loss: 73.8737 - acc: 0.7445 - val_loss: 63.1660 - val_acc: 0.7805\n",
      "Epoch 3/8\n",
      "40500/40500 [==============================] - 30s 747us/sample - loss: 73.1054 - acc: 0.7467 - val_loss: 63.2166 - val_acc: 0.7794\n",
      "Epoch 00003: early stopping\n",
      "Pass n° 5 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/10\n",
      "40500/40500 [==============================] - 30s 749us/sample - loss: 79.1331 - acc: 0.7245 - val_loss: 67.7529 - val_acc: 0.7646\n",
      "Epoch 2/10\n",
      "40500/40500 [==============================] - 30s 745us/sample - loss: 77.0616 - acc: 0.7317 - val_loss: 67.9272 - val_acc: 0.7626\n",
      "Epoch 3/10\n",
      "40500/40500 [==============================] - 30s 752us/sample - loss: 76.3043 - acc: 0.7342 - val_loss: 68.1166 - val_acc: 0.7611\n",
      "Epoch 00003: early stopping\n",
      "Pass n° 6 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/10\n",
      "40500/40500 [==============================] - 30s 746us/sample - loss: 89.5834 - acc: 0.6875 - val_loss: 79.7869 - val_acc: 0.7224\n",
      "Epoch 2/10\n",
      "40500/40500 [==============================] - 30s 745us/sample - loss: 87.3593 - acc: 0.6958 - val_loss: 80.0764 - val_acc: 0.7195\n",
      "Epoch 3/10\n",
      "40500/40500 [==============================] - 30s 746us/sample - loss: 86.5201 - acc: 0.6988 - val_loss: 80.3732 - val_acc: 0.7174\n",
      "Epoch 00003: early stopping\n",
      "Pass n° 7 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/10\n",
      "40500/40500 [==============================] - 30s 750us/sample - loss: 99.8232 - acc: 0.6520 - val_loss: 90.9214 - val_acc: 0.6836\n",
      "Epoch 2/10\n",
      "40500/40500 [==============================] - 30s 748us/sample - loss: 97.2730 - acc: 0.6624 - val_loss: 91.2393 - val_acc: 0.6807\n",
      "Epoch 3/10\n",
      "40500/40500 [==============================] - 30s 751us/sample - loss: 96.3963 - acc: 0.6656 - val_loss: 91.6382 - val_acc: 0.6782\n",
      "Epoch 00003: early stopping\n",
      "Pass n° 8 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/10\n",
      "40500/40500 [==============================] - 30s 746us/sample - loss: 119.0731 - acc: 0.5891 - val_loss: 111.5979 - val_acc: 0.6159\n",
      "Epoch 2/10\n",
      "40500/40500 [==============================] - 30s 752us/sample - loss: 116.3576 - acc: 0.6008 - val_loss: 112.0294 - val_acc: 0.6126\n",
      "Epoch 3/10\n",
      "40500/40500 [==============================] - 31s 758us/sample - loss: 115.4098 - acc: 0.6043 - val_loss: 112.4901 - val_acc: 0.6097\n",
      "Epoch 00003: early stopping\n",
      "Pass n° 9 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/10\n",
      "40500/40500 [==============================] - 30s 750us/sample - loss: 136.6676 - acc: 0.5343 - val_loss: 130.2583 - val_acc: 0.5568\n",
      "Epoch 2/10\n",
      "40500/40500 [==============================] - 30s 751us/sample - loss: 133.8425 - acc: 0.5468 - val_loss: 130.6208 - val_acc: 0.5542\n",
      "Epoch 3/10\n",
      "40500/40500 [==============================] - 32s 796us/sample - loss: 132.7126 - acc: 0.5516 - val_loss: 131.1746 - val_acc: 0.5509\n",
      "Epoch 00003: early stopping\n",
      "Pass n° 10 ...\n",
      "Train on 40500 samples, validate on 40500 samples\n",
      "Epoch 1/10\n",
      "40500/40500 [==============================] - 30s 752us/sample - loss: 159.8666 - acc: 0.4650 - val_loss: 154.4754 - val_acc: 0.4843\n",
      "Epoch 2/10\n",
      "40500/40500 [==============================] - 30s 748us/sample - loss: 156.9727 - acc: 0.4780 - val_loss: 154.8112 - val_acc: 0.4819\n",
      "Epoch 3/10\n",
      "40500/40500 [==============================] - 30s 749us/sample - loss: 155.7434 - acc: 0.4839 - val_loss: 155.4046 - val_acc: 0.4783\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "early_stop = EarlyStopping(patience=2, verbose=1)\n",
    "\n",
    "i = 1\n",
    "for nb_epochs, nb_delete in zip(\n",
    "        [1, 2, 3, 4, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],  # epochs for each round\n",
    "        [1, 2, 3, 4, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 45, 50, 55]  # digit to pull off\n",
    "):\n",
    "    print('Pass n° {} ...'.format(i))\n",
    "    i += 1\n",
    "    \n",
    "    model.fit(\n",
    "        delete_digits(X_train, nb_delete),  # delete digits from training sample\n",
    "        y_train,\n",
    "        validation_data=(\n",
    "            delete_digits(X_val, nb_delete), # delete same amount of digit from validation sample\n",
    "            y_val),\n",
    "        batch_size=128,\n",
    "        epochs=nb_epochs,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid solved:\t 100\n",
      "Correct ones:\t 0\n",
      "Accuracy:\t 0.0\n",
      "\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = list(map(from_one_hot, iterative_predict(X_test[:100], model)))\n",
    "# deltas = total_diff(from_one_hot(y_test) + 1, predictions)\n",
    "deltas = [correct_solution(from_one_hot(puzzle), solution) for puzzle, solution in zip(X_test[:100], predictions)]\n",
    "accuracy = np.mean(deltas)\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "Grid solved:\\t {}\n",
    "Correct ones:\\t {}\n",
    "Accuracy:\\t {}\n",
    "\"\"\".format(len(deltas), np.sum(deltas), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
